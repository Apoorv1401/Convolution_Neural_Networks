{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_processing_with_Open_CV_and_KNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN9VgCJxNJi8yZmU3A/X2AA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Apoorv1401/Convolution_Neural_Networks/blob/main/Image_processing_with_Open_CV_and_KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aMA7nAvQb6t"
      },
      "source": [
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh_m3lcR0n5i"
      },
      "source": [
        "#We will make a processor function for preprocessing the images as CNN requires all images in dataset to have a fixed feature and size\n",
        "#for images we have to preprocess our images to have same width and height\n",
        "def preprocess(image, width, height, inter = cv2.INTER_AREA): #interpolation is used to control the algorithm used for resizing\n",
        "  #resizing the image\n",
        "  return cv2.resize(image, (height, width), interpolation=inter)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY8yLHb3brb6"
      },
      "source": [
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej-7fX7ZTxri"
      },
      "source": [
        "#Function for loading our dataset\n",
        "def loading_dataset(imagePaths, width, height, verbose = -1): #verbose is used here to give us a update as to how many images processed\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  for i, imagePath in enumerate(imagePaths):\n",
        "    \n",
        "    image = cv2.imread(imagePath)\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "    \n",
        "    image = preprocess(image, width, height)\n",
        "\n",
        "    data.append(image)\n",
        "    labels.append(label)\n",
        "    if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
        "      print(\"[INFO] processed {}/{}\".format(i + 1,\n",
        "      len(imagePaths)))\n",
        "  return (np.array(data), np.array(labels))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "JAeFpW38Yxle",
        "outputId": "5e1d0070-0320-4542-a449-fd22f4988b39"
      },
      "source": [
        "'''So we have basically five steps to perform:\n",
        "load dataset\n",
        "preprocess the image\n",
        "split the dataset\n",
        "train the classifier\n",
        "determine the accuracy\n",
        "'''"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'So we have basically five steps to perform:\\nload dataset\\npreprocess the image\\nsplit the dataset\\ntrain the classifier\\ndetermine the accuracy\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "NwsDhHh5e6mz",
        "outputId": "44ac0678-50a6-43db-fb2b-23796b53d4a1"
      },
      "source": [
        "'''WE need the following packages\n",
        "KNeighborsClassifier for the implementation of the KNN algorithm\n",
        "LabelEncoder for converting our labels which are strings to integers\n",
        "train_test_split function for dividing the dataset into training and testing sets\n",
        "'''"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'WE need the following packages\\nKNeighborsClassifier for the implementation of the KNN algorithm\\nLabelEncoder for converting our labels which are strings to integers\\ntrain_test_split function for dividing the dataset into training and testing sets\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBcuIvbbgFNP"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imutils import paths"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9G-vuAvgQIc",
        "outputId": "aaf68299-6d9e-4fca-bfa9-c581f386779f"
      },
      "source": [
        "#Lets load the images\n",
        "print('Loading Images')\n",
        "imagePaths = list(paths.list_images('/content/sample_data/Dataset'))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07sX4PDbhO-G",
        "outputId": "e7cac841-3ebf-4c99-c851-8ba0641bf56e"
      },
      "source": [
        "len(imagePaths)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evrBubeZhTob",
        "outputId": "65f6886e-8d94-4650-c2ab-b73c3940c779"
      },
      "source": [
        "(data, labels) = loading_dataset(imagePaths, 32, 32, verbose=150)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] processed 150/3000\n",
            "[INFO] processed 300/3000\n",
            "[INFO] processed 450/3000\n",
            "[INFO] processed 600/3000\n",
            "[INFO] processed 750/3000\n",
            "[INFO] processed 900/3000\n",
            "[INFO] processed 1050/3000\n",
            "[INFO] processed 1200/3000\n",
            "[INFO] processed 1350/3000\n",
            "[INFO] processed 1500/3000\n",
            "[INFO] processed 1650/3000\n",
            "[INFO] processed 1800/3000\n",
            "[INFO] processed 1950/3000\n",
            "[INFO] processed 2100/3000\n",
            "[INFO] processed 2250/3000\n",
            "[INFO] processed 2400/3000\n",
            "[INFO] processed 2550/3000\n",
            "[INFO] processed 2700/3000\n",
            "[INFO] processed 2850/3000\n",
            "[INFO] processed 3000/3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC2N2YrsitBY",
        "outputId": "203b8653-0ffd-4195-d340-be236a196846"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QahZi1ZWz07H",
        "outputId": "278d02f2-89dc-4905-d881-4b824d45e71f"
      },
      "source": [
        "labels[:5]\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Cats', 'Cats', 'Cats', 'Cats', 'Cats'], dtype='<U6')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtf2TVPllfck"
      },
      "source": [
        "#For applying the KNN algorithm we need our data to be a single list of pixel intensities\n",
        "#for that purpose we will use the reshape function in numpy"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or5RWJlZoibg"
      },
      "source": [
        "data = data.reshape((data.shape[0], 3072))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBE2-yICzVPu",
        "outputId": "3efd65b5-c384-43a6-deda-eeac0e26990a"
      },
      "source": [
        "data.shape\n",
        "#the image is not changed just the data is represented as 3000 images of 3072 dimension (32*32*3)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 3072)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yZWKE0EzJuD"
      },
      "source": [
        "le = LabelEncoder()\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POUcwpfuzpJh"
      },
      "source": [
        "labels = le.fit_transform(labels)\n",
        "#what this step does is change the labels to integers for example: Cats to 0, Dogs to 1, Pandas to 2"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE71dBWZzxg_",
        "outputId": "5b2a9d4b-9e4c-4422-8513-c8187ce02dc2"
      },
      "source": [
        "labels[:5]\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j3BpZ9x0OCI"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state = 123)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArmP8aBx08rV",
        "outputId": "c77784e3-3e92-4bdd-8be2-af297e1517c9"
      },
      "source": [
        "#Fitting the KNN classifier and evaluating it\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_model.fit(X_train, y_train)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVbI3JP81-ds"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "#to Evaluate the performance of our model and have a formatted report in tabular format"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhfSDuvt2GS8",
        "outputId": "e303451c-f4c7-46b2-d544-e151750e4fe9"
      },
      "source": [
        "print(classification_report(y_test, knn_model.predict(X_test),\n",
        " target_names=le.classes_))\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Cats       0.38      0.54      0.45       252\n",
            "        Dogs       0.39      0.47      0.43       240\n",
            "      Pandas       0.84      0.35      0.50       258\n",
            "\n",
            "    accuracy                           0.45       750\n",
            "   macro avg       0.54      0.45      0.46       750\n",
            "weighted avg       0.54      0.45      0.46       750\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUsDL6lS2XPi"
      },
      "source": [
        "#now we see that the accuracy is 54% which is not bad for a classifier that does not learn at all\n",
        "#also we can notice that the Pandas were coorectly identified 84% of the time, probably because they look quite different from dogs and cats\n",
        "#dogs and cats on the other hand were classified correctly 39% and 38%. It can be because their fur are quite similar in their shades and color.\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STsF1Zi33WJy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}